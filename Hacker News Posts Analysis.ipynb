{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Post Analysis\n",
    "\n",
    "### Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first few rows of the dataset:\n",
      "\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'] \n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'] \n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'] \n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'] \n",
      "\n",
      "Header row is: ['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "The first three rows of the dataset sans the header row:\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'] \n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'] \n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'] \n",
      "\n",
      "The number of datapoints in the dataset are: 293119\n"
     ]
    }
   ],
   "source": [
    "# Opening the dataset\n",
    "from csv import reader\n",
    "open_db = open(r'C:\\Users\\Official\\Desktop\\Dataset\\Hacker News Posts\\HN_posts_year_to_Sep_26_2016.csv',encoding='utf8',errors='ignore')\n",
    "read_db=reader(open_db)\n",
    "raw_data=list(read_db)\n",
    "\n",
    "print(\"The first few rows of the dataset:\\n\")\n",
    "for row in raw_data[:5]:\n",
    "    print(row,'\\n')\n",
    "\n",
    "# Extracting header row\n",
    "header=raw_data[0]\n",
    "print(\"Header row is:\",header,\"\\n\")\n",
    "\n",
    "# Excluding header row from the dataset\n",
    "raw_data=raw_data[1:]\n",
    "print(\"The first three rows of the dataset sans the header row:\\n\")\n",
    "for row in raw_data[:3]:\n",
    "    print(row,'\\n')\n",
    "\n",
    "# Number of datapoints/rows in the dataset\n",
    "print(\"The number of datapoints in the dataset are:\",len(raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segregating the data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first few rows of the Ask HN posts dataset:\n",
      "\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57']\n",
      "\n",
      "The first few rows of the Show HN posts dataset:\n",
      "\n",
      "['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36']\n",
      "['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']\n",
      "['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']\n",
      "\n",
      "The first few rows of the Other posts dataset:\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "The number of rows in the Ask HN posts dataset: 9139 \n",
      "\n",
      "The number of rows in the Show HN posts dataset: 10158 \n",
      "\n",
      "The number of rows in the Other posts dataset: 273822 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_posts=[]\n",
    "show_posts=[]\n",
    "other_posts=[]\n",
    "\n",
    "for row in raw_data:\n",
    "    title=row[1]\n",
    "    title=title.lower()\n",
    "    if (title.startswith('ask hn')):\n",
    "        ask_posts.append(row)\n",
    "    elif (title.startswith('show hn')):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "# Print few rows of the isolated datasets\n",
    "print(\"The first few rows of the Ask HN posts dataset:\\n\")\n",
    "for row in ask_posts[:3]:\n",
    "    print(row)\n",
    "\n",
    "print(\"\\nThe first few rows of the Show HN posts dataset:\\n\")\n",
    "for row in show_posts[:3]:\n",
    "    print(row)\n",
    "\n",
    "print(\"\\nThe first few rows of the Other posts dataset:\\n\")\n",
    "for row in other_posts[:3]:\n",
    "    print(row)\n",
    "    \n",
    "# Number of rows in the dataset\n",
    "print(\"\\nThe number of rows in the Ask HN posts dataset:\",len(ask_posts),\"\\n\")\n",
    "print(\"The number of rows in the Show HN posts dataset:\",len(show_posts),\"\\n\")\n",
    "print(\"The number of rows in the Other posts dataset:\",len(other_posts),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the average number of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments per post for 'Ask HN' posts are:  10.393478498741656\n",
      "The average number of comments per post for 'Show HN' posts are:  4.886099625910612\n",
      "The average number of comments per post for Other posts are:  6.4572678601427205\n"
     ]
    }
   ],
   "source": [
    "# For Ask HN Posts\n",
    "ask_comments_total=0\n",
    "for row in ask_posts:\n",
    "    comment=int(row[4])\n",
    "    ask_comments_total+=comment\n",
    "avg_ask_comments=ask_comments_total/len(ask_posts)\n",
    "print(\"The average number of comments per post for 'Ask HN' posts are: \",avg_ask_comments)\n",
    "\n",
    "# For Show HN Posts\n",
    "show_comments_total=0\n",
    "for row in show_posts:\n",
    "    comment=int(row[4])\n",
    "    show_comments_total+=comment\n",
    "avg_show_comments=show_comments_total/len(show_posts)\n",
    "print(\"The average number of comments per post for 'Show HN' posts are: \",avg_show_comments)\n",
    "\n",
    "# For Other Posts\n",
    "other_comments_total=0\n",
    "for row in other_posts:\n",
    "    comment=int(row[4])\n",
    "    other_comments_total+=comment\n",
    "avg_other_comments=other_comments_total/len(other_posts)\n",
    "print(\"The average number of comments per post for Other posts are: \",avg_other_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the amount of 'Ask HN' posts & comments per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few elements of the isolated list of creation time of post and the number of posts:\n",
      "[[datetime.datetime(2016, 9, 26, 2, 53), 7], [datetime.datetime(2016, 9, 26, 1, 17), 3], [datetime.datetime(2016, 9, 25, 22, 57), 0]]\n",
      "\n",
      "Number of posts by hour:\n",
      "[(646, 15), (614, 18), (587, 17), (579, 16), (552, 19), (518, 21), (513, 14), (510, 20), (444, 13), (383, 22), (343, 23), (342, 12), (312, 11), (301, 0), (282, 10), (282, 1), (271, 3), (269, 2), (257, 8), (243, 4), (234, 6), (226, 7), (222, 9), (209, 5)]\n",
      "\n",
      "Number of comments by hour:\n",
      "[(18525, 15), (7245, 13), (5547, 17), (4972, 14), (4877, 18), (4500, 21), (4466, 16), (4462, 20), (4234, 12), (3954, 19), (3372, 22), (3013, 10), (2996, 2), (2797, 11), (2362, 8), (2360, 4), (2297, 23), (2277, 0), (2154, 3), (2089, 1), (1838, 5), (1587, 6), (1585, 7), (1477, 9)]\n",
      "\n",
      "Average number of comments per hour per post:\n",
      "[[28.676470588235293, 15], [16.31756756756757, 13], [12.380116959064328, 12], [11.137546468401487, 2], [10.684397163120567, 10], [9.7119341563786, 4], [9.692007797270955, 14], [9.449744463373083, 17], [9.190661478599221, 8], [8.96474358974359, 11], [8.804177545691905, 22], [8.794258373205741, 5], [8.749019607843136, 20], [8.687258687258687, 21], [7.948339483394834, 3], [7.94299674267101, 18], [7.713298791018998, 16], [7.5647840531561465, 0], [7.407801418439717, 1], [7.163043478260869, 19], [7.013274336283186, 7], [6.782051282051282, 6], [6.696793002915452, 23], [6.653153153153153, 9]]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list=[]\n",
    "for row in ask_posts:\n",
    "    created_at=row[6]\n",
    "    created_at=dt.datetime.strptime(created_at, \"%m/%d/%Y %H:%M\")\n",
    "    comments=int(row[4])\n",
    "    dummy_list=[created_at,comments]\n",
    "    result_list.append(dummy_list)\n",
    "print(\"First few elements of the isolated list of creation time of post and the number of posts:\")\n",
    "print(result_list[:3])\n",
    "\n",
    "counts_by_hour={}\n",
    "comments_by_hour={}\n",
    "for element in result_list:\n",
    "    date_time=element[0]\n",
    "    num_comments=element[1]\n",
    "    hour=date_time.hour\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour]=1\n",
    "        comments_by_hour[hour]=num_comments\n",
    "    else:\n",
    "        counts_by_hour[hour]+=1\n",
    "        comments_by_hour[hour]+=num_comments\n",
    "\n",
    "counts_table_display=[]\n",
    "for key in counts_by_hour:\n",
    "    key_val_as_tuple=(counts_by_hour[key],key)\n",
    "    counts_table_display.append(key_val_as_tuple)\n",
    "counts_table_sorted=sorted(counts_table_display,reverse=True)\n",
    "print(\"\\nNumber of posts by hour:\")\n",
    "print(counts_table_sorted)\n",
    "\n",
    "comments_table_display=[]\n",
    "for key in comments_by_hour:\n",
    "    key_val_as_tuple=(comments_by_hour[key],key)\n",
    "    comments_table_display.append(key_val_as_tuple)\n",
    "comments_table_sorted=sorted(comments_table_display,reverse=True)\n",
    "print(\"\\nNumber of comments by hour:\")\n",
    "print(comments_table_sorted)\n",
    "\n",
    "avg_by_hour=[]\n",
    "for hour in comments_by_hour:\n",
    "    avg=comments_by_hour[hour]/counts_by_hour[hour]\n",
    "    avg_by_hour.append([avg,hour])\n",
    "avg_by_hour=sorted(avg_by_hour,reverse=True)\n",
    "\n",
    "print(\"\\nAverage number of comments per hour per post:\")\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle result to another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The imported list of comments by hour:\n",
      " [[(18525, 15), (7245, 13), (5547, 17), (4972, 14), (4877, 18), (4500, 21), (4466, 16), (4462, 20), (4234, 12), (3954, 19), (3372, 22), (3013, 10), (2996, 2), (2797, 11), (2362, 8), (2360, 4), (2297, 23), (2277, 0), (2154, 3), (2089, 1), (1838, 5), (1587, 6), (1585, 7), (1477, 9)], [(646, 15), (614, 18), (587, 17), (579, 16), (552, 19), (518, 21), (513, 14), (510, 20), (444, 13), (383, 22), (343, 23), (342, 12), (312, 11), (301, 0), (282, 10), (282, 1), (271, 3), (269, 2), (257, 8), (243, 4), (234, 6), (226, 7), (222, 9), (209, 5)], [[28.676470588235293, 15], [16.31756756756757, 13], [12.380116959064328, 12], [11.137546468401487, 2], [10.684397163120567, 10], [9.7119341563786, 4], [9.692007797270955, 14], [9.449744463373083, 17], [9.190661478599221, 8], [8.96474358974359, 11], [8.804177545691905, 22], [8.794258373205741, 5], [8.749019607843136, 20], [8.687258687258687, 21], [7.948339483394834, 3], [7.94299674267101, 18], [7.713298791018998, 16], [7.5647840531561465, 0], [7.407801418439717, 1], [7.163043478260869, 19], [7.013274336283186, 7], [6.782051282051282, 6], [6.696793002915452, 23], [6.653153153153153, 9]]]\n",
      "\n",
      "Check if the imported and exported lists of comments by hour are the same: True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename='hacker_news_pickle'\n",
    "outfile=open(filename,'wb')\n",
    "result_variables=[comments_table_sorted,counts_table_sorted,avg_by_hour]\n",
    "pickle.dump(result_variables,outfile)\n",
    "outfile.close()\n",
    "\n",
    "# Checking pickled data by importing\n",
    "infile=open(filename,'rb')\n",
    "new_list=pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "print(\"The imported list of comments by hour:\\n\",new_list)\n",
    "print(\"\\nCheck if the imported and exported lists of comments by hour are the same:\",new_list[0]==comments_table_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
